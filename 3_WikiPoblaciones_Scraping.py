import requests
from bs4 import BeautifulSoup
from urllib.parse import quote
from colorama import init, Fore, Style
import re

# Inicializa colorama para colorear la salida en terminales compatibles (especialmente en Windows)
init(autoreset=True)

def mostrar_banner():
    """
    Muestra un banner decorativo en la consola para dar la bienvenida al usuario.
    Utiliza colores y estilos para mejorar la presentaciÃ³n.
    """
    banner = f"""
{Fore.CYAN}{Style.BRIGHT}
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸŒ Buscador de Poblaciones - Wikipedia Edition  ğŸŒ â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘   Â¡Descubre la poblaciÃ³n de tu ciudad favorita!     â•‘
â•‘          Disfruta de una experiencia amigable       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{Style.RESET_ALL}
    """
    print(banner)

def obtener_pagina_wikipedia(poblacion):
    """
    Busca la pÃ¡gina de Wikipedia correspondiente a la poblaciÃ³n introducida.
    - Primero intenta acceder directamente a la URL de la poblaciÃ³n.
    - Si no existe, realiza una bÃºsqueda en Wikipedia.
    - Todas las peticiones tienen un timeout de 10 segundos.
    Devuelve el HTML de la pÃ¡gina encontrada y la URL usada.
    """
    # Formatea el nombre de la poblaciÃ³n para construir la URL directa
    poblacion_formateada = poblacion.title().replace(" ", "_")
    url_directa = f"https://es.wikipedia.org/wiki/{quote(poblacion_formateada)}"
    
    try:
        # Intenta acceder a la pÃ¡gina directa
        response = requests.get(url_directa, timeout=10)
        if response.status_code == 200:
            return response.text, url_directa
        else:
            # Si no existe, busca usando el motor de bÃºsqueda de Wikipedia
            print(Fore.YELLOW + "ğŸ˜® No se encontrÃ³ la pÃ¡gina directa, buscando a travÃ©s de Wikipedia...")
            url_busqueda = f"https://es.wikipedia.org/w/index.php?search={quote(poblacion)}"
            response = requests.get(url_busqueda, timeout=10)
            if response.status_code == 200:
                return response.text, response.url
            else:
                print(Fore.RED + "ğŸš¨ Error al acceder a Wikipedia. Â¡IntÃ©ntalo de nuevo mÃ¡s tarde!")
                exit(1)
    except requests.exceptions.Timeout:
        print(Fore.RED + "ğŸš¨ Tiempo de espera agotado al conectar con Wikipedia. Comprueba tu conexiÃ³n a internet.")
        exit(1)
    except requests.exceptions.RequestException as e:
        print(Fore.RED + f"ğŸš¨ Error al conectar con Wikipedia: {e}")
        exit(1)

def manejar_desambiguacion(soup, poblacion):
    """
    Si la pÃ¡gina es de desambiguaciÃ³n, muestra las opciones disponibles y permite al usuario elegir.
    Devuelve el HTML de la opciÃ³n seleccionada o None si se cancela.
    """
    print(Fore.YELLOW + "ğŸ¤” Se detectÃ³ pÃ¡gina de desambiguaciÃ³n. Hay mÃºltiples opciones:")
    items = soup.select(".mw-parser-output > ul li")
    
    opciones_validas = []
    # Recorre las opciones de la lista y las muestra al usuario
    for idx, item in enumerate(items, 1):
        texto_item = item.get_text(" ", strip=True)
        link = item.find("a", href=True)
        if link and not link['href'].startswith('#'):
            print(f"{Fore.CYAN}{idx}.{Style.RESET_ALL} {texto_item}")
            opciones_validas.append((idx, "https://es.wikipedia.org" + link['href'], texto_item))
    
    if not opciones_validas:
        print(Fore.RED + "ğŸ˜• No se encontraron opciones vÃ¡lidas en la pÃ¡gina de desambiguaciÃ³n.")
        return None
        
    while True:
        try:
            eleccion = input(Fore.GREEN + "Elige una opciÃ³n (nÃºmero) o '0' para cancelar: ")
            if eleccion == '0':
                return None
                
            eleccion = int(eleccion)
            for idx, url, texto in opciones_validas:
                if idx == eleccion:
                    print(Fore.GREEN + f"Seleccionaste: {texto}")
                    try:
                        response = requests.get(url, timeout=10)
                        if response.status_code == 200:
                            return response.text
                    except (requests.exceptions.RequestException, requests.exceptions.Timeout):
                        print(Fore.RED + "ğŸš¨ Error al acceder a la pÃ¡gina seleccionada.")
                        return None
            
            print(Fore.RED + "âŒ OpciÃ³n no vÃ¡lida. Intenta de nuevo.")
        except ValueError:
            print(Fore.RED + "âŒ Por favor, introduce un nÃºmero vÃ¡lido.")

def extraer_info_adicional(soup):
    """
    Extrae informaciÃ³n adicional de la infobox o del contenido principal:
    - Superficie
    - Densidad de poblaciÃ³n
    Devuelve un diccionario con los datos encontrados.
    """
    info = {"superficie": None, "densidad": None}
    infobox = soup.find("table", {"class": "infobox"})
    
    # Busca en la infobox
    if infobox:
        for fila in infobox.find_all("tr"):
            if fila.th and fila.td:
                etiqueta = fila.th.get_text(" ", strip=True).lower()
                if "superficie" in etiqueta:
                    info["superficie"] = fila.td.get_text(" ", strip=True)
                elif "densidad" in etiqueta:
                    info["densidad"] = fila.td.get_text(" ", strip=True)
    
    # Si no encuentra, busca en los primeros pÃ¡rrafos
    if not info["superficie"] or not info["densidad"]:
        parrafos = soup.select(".mw-parser-output > p")
        for p in parrafos:
            texto = p.get_text(" ", strip=True).lower()
            if not info["superficie"] and "superficie" in texto and re.search(r'\d+\s*km', texto):
                match = re.search(r'superficie\s*(?:de|es|:)?\s*([^\.;]+(?:km|hectÃ¡reas|ha))', texto, re.IGNORECASE)
                if match:
                    info["superficie"] = match.group(1).strip()
            
            if not info["densidad"] and "densidad" in texto and re.search(r'\d+\s*hab', texto):
                match = re.search(r'densidad\s*(?:de|es|:)?\s*([^\.;]+(?:hab|habitantes))', texto, re.IGNORECASE)
                if match:
                    info["densidad"] = match.group(1).strip()
    
    return info

def extraer_poblacion(html):
    """
    Extrae la poblaciÃ³n de la pÃ¡gina HTML.
    - Busca primero en la infobox.
    - Si no existe, permite elegir al usuario en caso de desambiguaciÃ³n.
    - Si tampoco, intenta buscar en el contenido principal.
    Devuelve la poblaciÃ³n y un diccionario con informaciÃ³n adicional.
    """
    soup = BeautifulSoup(html, "html.parser")
    infobox = soup.find("table", {"class": "infobox"})
    
    # Si no hay infobox, puede ser desambiguaciÃ³n o buscar en el contenido principal
    if not infobox:
        if "puede referirse a:" in soup.text.lower():
            nuevo_html = manejar_desambiguacion(soup, "")
            if nuevo_html:
                return extraer_poblacion(nuevo_html)
            else:
                return None, {}
        else:
            # Busca en los pÃ¡rrafos principales
            poblacion = buscar_poblacion_en_contenido(soup)
            if poblacion:
                info_adicional = extraer_info_adicional(soup)
                return poblacion, info_adicional
            print(Fore.YELLOW + "ğŸ˜• No se encontrÃ³ la infobox en la pÃ¡gina.")
            return None, {}

    # Busca filas de la infobox relacionadas con poblaciÃ³n o habitantes
    candidates = []
    for fila in infobox.find_all("tr"):
        if fila.th and fila.td:
            etiqueta = fila.th.get_text(" ", strip=True).lower()
            if "poblaciÃ³n" in etiqueta or "habitantes" in etiqueta:
                texto = fila.td.get_text(" ", strip=True)
                if re.search(r'\d', texto):
                    candidates.append(texto)
    
    # Prioriza los candidatos que incluyan "hab"
    for cand in candidates:
        if "hab" in cand.lower():
            info_adicional = extraer_info_adicional(soup)
            return cand, info_adicional

    # Si no, elige el candidato con mÃ¡s dÃ­gitos
    best_candidate = None
    max_digits = 0
    for cand in candidates:
        digits = re.findall(r'\d+', cand)
        total_digits = sum(len(d) for d in digits)
        if total_digits > max_digits:
            max_digits = total_digits
            best_candidate = cand
    
    # Si no hay nada en la infobox, busca en el contenido principal
    if not best_candidate:
        best_candidate = buscar_poblacion_en_contenido(soup)
    
    info_adicional = extraer_info_adicional(soup)
    return best_candidate, info_adicional

def buscar_poblacion_en_contenido(soup):
    """
    Busca informaciÃ³n de poblaciÃ³n en los primeros pÃ¡rrafos del artÃ­culo.
    Utiliza expresiones regulares para encontrar frases tÃ­picas de poblaciÃ³n.
    """
    parrafos = soup.select(".mw-parser-output > p")
    for p in parrafos[:5]:  # Solo los primeros pÃ¡rrafos para eficiencia
        texto = p.get_text(" ", strip=True).lower()
        if ("poblaciÃ³n" in texto or "habitantes" in texto) and re.search(r'\d+\s*hab', texto):
            match = re.search(r'(?:poblaciÃ³n|habitantes)[^\.;]*?(\d[\d\s\.\,]*\s*hab[^\d]*(?:\d{4})?)', texto)
            if match:
                return match.group(1).strip()
    return None

def main():
    """
    FunciÃ³n principal del programa.
    - Muestra el banner.
    - Pide al usuario el nombre de la poblaciÃ³n.
    - Busca y muestra la poblaciÃ³n, superficie y densidad.
    - Permite salir escribiendo 'salir'.
    """
    mostrar_banner()
    while True:
        mensaje = (Fore.CYAN + Style.BRIGHT +
                   "ğŸ‘‰  Introduce el nombre de la poblaciÃ³n (o escribe 'salir' para terminar): " +
                   Style.RESET_ALL)
        poblacion = input(mensaje).strip()
        if poblacion.lower() == "salir":
            print(Fore.CYAN + "\nÂ¡Hasta la prÃ³xima! ğŸ‘‹ğŸ˜Š")
            break

        html, url_obtenida = obtener_pagina_wikipedia(poblacion)
        print(Fore.GREEN + f"\nğŸ” Consultando la pÃ¡gina: {url_obtenida}\n")

        poblacion_extraida, info_adicional = extraer_poblacion(html)
        if poblacion_extraida:
            print(Fore.MAGENTA + Style.BRIGHT +
                  f"ğŸ™ï¸  La poblaciÃ³n de {poblacion.title()} es: {poblacion_extraida}")
            
            # Muestra informaciÃ³n adicional si estÃ¡ disponible
            if info_adicional["superficie"]:
                print(Fore.MAGENTA + f"ğŸ“ Superficie: {info_adicional['superficie']}")
            if info_adicional["densidad"]:
                print(Fore.MAGENTA + f"ğŸ§® Densidad: {info_adicional['densidad']}")
            print()
        else:
            print(Fore.RED + "ğŸš¨ No se pudo extraer la informaciÃ³n de poblaciÃ³n.\n")

if __name__ == "__main__":
    main()
